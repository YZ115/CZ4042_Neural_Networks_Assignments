{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Project 2, starter code Part a\n",
    "#\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras import models\n",
    "from skimage import color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "\n",
      " [name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3048682292\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2134594655154387937\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# This is required when using GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(gpus)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        devices = device_lib.list_local_devices()\n",
    "        avail_gpu = [x for x in devices if x.device_type == 'GPU']\n",
    "        print('\\n',avail_gpu)\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No gpus available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed, no need change\n",
    "def load_data(file):\n",
    "    file = 'data\\\\'+file\n",
    "    with open(file, 'rb') as fo:\n",
    "        try:\n",
    "            samples = pickle.load(fo)\n",
    "        except UnicodeDecodeError:  # python 3.x\n",
    "            fo.seek(0)\n",
    "            samples = pickle.load(fo, encoding='latin1')\n",
    "\n",
    "    data, labels = samples['data'], samples['labels']\n",
    "\n",
    "    data = np.array(data, dtype=np.float32) / 255\n",
    "    data = tf.reshape(data, [-1,3, 32, 32])\n",
    "    data = tf.transpose(data,(0,2,3,1))\n",
    "    labels = np.array(labels, dtype=np.int32)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class History_trained_model(object):\n",
    "    def __init__(self, history, epoch, params):\n",
    "        self.history = history\n",
    "        self.epoch = epoch\n",
    "        self.params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(num_ch_c1, num_ch_c2, use_dropout):\n",
    "    ''' Note: This model is incomplete. You need to add suitable layers.\n",
    "    '''\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Input(shape=(32,32,3)))\n",
    "    model.add(layers.Conv2D(num_ch_c1, 9, padding='valid', activation='relu', input_shape=(None, None, 3)))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
    "    model.add(layers.Conv2D(num_ch_c2, 5, padding='valid', activation='relu'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(300, activation=None))\n",
    "    model.add(layers.Dense(10, use_bias=True, activation='softmax', input_shape=(300,)))  # Here no softmax because we have combined it with the loss\n",
    "    return model\n",
    "#model = make_model(50,60,False)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(num_ch_c1,num_ch_c2,optimizer_,use_dropout):\n",
    "    # Create folder to store models and results\n",
    "    if not os.path.exists('./models'):\n",
    "        os.mkdir('./models')\n",
    "    if not os.path.exists('./results'):\n",
    "        os.mkdir('./results')\n",
    "     \n",
    "    # Save model\n",
    "    if use_dropout:\n",
    "        model.save(f'./models/QuestionA2_{num_ch_c1}_{num_ch_c2}_{optimizer_}_dropout')\n",
    "        with open(f'histories/{num_ch_c1}_{num_ch_c2}_{optimizer_}_dropout', 'wb') as file_pi:\n",
    "            pickle.dump(history.history, file_pi)\n",
    "    else:\n",
    "        model.save(f'./models/QuestionA2_{num_ch_c1}_{num_ch_c2}_{optimizer_}_no_dropout')\n",
    "        with open(f'histories/{num_ch_c1}_{num_ch_c2}_{optimizer_}_nodropout', 'wb') as file_pi:\n",
    "            pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_opt(optimizer_,lr):\n",
    "    if optimizer_ == 'SGD':\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer_ == 'SGD-momentum':  # Question 3(a)\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=lr, momentum = 0.1)\n",
    "    elif optimizer_ == 'RMSProp':  # Question 3(b)\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    elif optimizer_ == 'Adam':  # Question 3(c)\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    else:\n",
    "        raise NotImplementedError(f'You do not need to handle [{optimizer_}] in this project.')\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plot for losses\n",
    "def plot_loss(loss,test_loss,use_dropout):\n",
    "    train_loss = loss\n",
    "    val_loss = test_loss\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(range(1, len(train_loss) + 1), train_loss, label='Train')\n",
    "    plt.plot(range(1, len(val_loss) + 1), val_loss, label='Test')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    if use_dropout:\n",
    "        plt.savefig(\n",
    "            f'./results/QuestionA3_{num_ch_c1}_{num_ch_c2}_{optimizer_}_dropout_loss.pdf')\n",
    "    else:\n",
    "        plt.savefig(\n",
    "            f'./results/QuestionA3_{num_ch_c1}_{num_ch_c2}_{optimizer_}_no_dropout_loss.pdf'\n",
    "        )\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plot for accuracy\n",
    "def plot_acc(acc,val_acc,use_dropout):\n",
    "    train_acc = acc\n",
    "    test_acc = val_acc\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(range(1, len(train_acc) + 1), train_acc, label='Train')\n",
    "    plt.plot(range(1, len(test_acc) + 1), test_acc, label='Test')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    if use_dropout:\n",
    "        plt.savefig(\n",
    "            f'./results/QuestionA2_{num_ch_c1}_{num_ch_c2}_{optimizer_}_dropout_accuracy.pdf'\n",
    "        )\n",
    "    else:\n",
    "        plt.savefig(\n",
    "            f'./results/QuestionA2_{num_ch_c1}_{num_ch_c2}_{optimizer_}_no_dropout_accuracy.pdf'\n",
    "        )\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "79/79 [==============================] - 5s 33ms/step - loss: 2.3092 - accuracy: 0.1031 - val_loss: 2.2963 - val_accuracy: 0.1460\n",
      "Epoch 2/500\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 2.2953 - accuracy: 0.1541 - val_loss: 2.2891 - val_accuracy: 0.1640\n",
      "Epoch 3/500\n",
      "31/79 [==========>...................] - ETA: 0s - loss: 2.2894 - accuracy: 0.1642"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Optimal Combination of Channels\n",
    "num_ch_c1 = 70  # Question 2\n",
    "num_ch_c2 = 60  # Question 2+\n",
    "\n",
    "optimizer_list = ['SGD','SGD-momentum','RMSProp','Adam']\n",
    "\n",
    "epochs = 500  # Fixed\n",
    "batch_size = 128  # Fixed\n",
    "learning_rate = 0.001\n",
    "#optimizer_ = 'SGD'  # Question 3\n",
    "use_dropout = False  # Question 3(d) (see make_model)\n",
    "\n",
    "x_train, y_train = load_data('data_batch_1')\n",
    "x_test, y_test = load_data('test_batch_trim')\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "for optimizer_ in optimizer_list:\n",
    "    # Initialize optimizer\n",
    "    optimizer = create_opt(optimizer_,learning_rate)\n",
    "    # Initialize model\n",
    "    model = make_model(num_ch_c1, num_ch_c2, use_dropout)\n",
    "\n",
    "    # Training\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_test, y_test))\n",
    "\n",
    "    save_model(num_ch_c1,num_ch_c2,optimizer_,use_dropout)\n",
    "\n",
    "    # Save the plot for losses\n",
    "    plot_loss(history.history['loss'],history.history['val_loss'],use_dropout)\n",
    "\n",
    "    # Save the plot for accuracies\n",
    "    plot_acc(history.history['accuracy'],history.history['val_accuracy'],use_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test[0].shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
